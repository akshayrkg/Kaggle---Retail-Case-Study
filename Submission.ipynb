{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import xgboost as xgb\n",
    "import pylab as pl\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wther2007=pd.read_excel('WeatherData.xlsx','2009')\n",
    "#Wther2008=pd.read_excel('WeatherData.xlsx','2010')\n",
    "Wther2009=pd.read_excel('WeatherData.xlsx','2011')\n",
    "Wther2010=pd.read_excel('WeatherData.xlsx','2012')\n",
    "Wther2011=pd.read_excel('WeatherData.xlsx','2013')\n",
    "Wther2012=pd.read_excel('WeatherData.xlsx','2014')\n",
    "Wther2013=pd.read_excel('WeatherData.xlsx','2015')\n",
    "Wther2014=pd.read_excel('WeatherData.xlsx','2016')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wther=Wther.drop(['Temp high (°C)','Temp low (°C)','Dew Point high (°C)','Dew Point low (°C)','Humidity\\xa0(%) high','Humidity\\xa0(%) low','Sea Level Press.\\xa0(hPa) high','Sea Level Press.\\xa0(hPa) low','Visibility\\xa0(km) high','Visibility\\xa0(km) low','Wind\\xa0(km/h) high','Wind\\xa0(km/h) low','WeatherEvent','Precip.\\xa0(mm) sum'],axis=1)\n",
    "\n",
    "#Wther2007=Wther2007.drop(['Temp high (°C)','Temp low (°C)','Dew Point high (°C)','Dew Point low (°C)','Humidity\\xa0(%) high','Humidity\\xa0(%) low','Sea Level Press.\\xa0(hPa) high','Sea Level Press.\\xa0(hPa) low','Visibility\\xa0(km) high','Visibility\\xa0(km) low','Wind\\xa0(km/h) high','Wind\\xa0(km/h) low','WeatherEvent','Precip.\\xa0(mm) sum'],axis=1)\n",
    "#Wther2008=Wther2008.drop(['Temp high (°C)','Temp low (°C)','Dew Point high (°C)','Dew Point low (°C)','Humidity\\xa0(%) high','Humidity\\xa0(%) low','Sea Level Press.\\xa0(hPa) high','Sea Level Press.\\xa0(hPa) low','Visibility\\xa0(km) high','Visibility\\xa0(km) low','Wind\\xa0(km/h) high','Wind\\xa0(km/h) low','WeatherEvent','Precip.\\xa0(mm) sum'],axis=1)\n",
    "Wther2009=Wther2009.drop(['Temp high (°C)','Temp low (°C)','Dew Point high (°C)','Dew Point low (°C)','Humidity\\xa0(%) high','Humidity\\xa0(%) low','Sea Level Press.\\xa0(hPa) high','Sea Level Press.\\xa0(hPa) low','Visibility\\xa0(km) high','Visibility\\xa0(km) low','Wind\\xa0(km/h) high','Wind\\xa0(km/h) low','WeatherEvent','Precip.\\xa0(mm) sum'],axis=1)\n",
    "Wther2010=Wther2010.drop(['Temp high (°C)','Temp low (°C)','Dew Point high (°C)','Dew Point low (°C)','Humidity\\xa0(%) high','Humidity\\xa0(%) low','Sea Level Press.\\xa0(hPa) high','Sea Level Press.\\xa0(hPa) low','Visibility\\xa0(km) high','Visibility\\xa0(km) low','Wind\\xa0(km/h) high','Wind\\xa0(km/h) low','WeatherEvent','Precip.\\xa0(mm) sum'],axis=1)\n",
    "Wther2011=Wther2011.drop(['Temp high (°C)','Temp low (°C)','Dew Point high (°C)','Dew Point low (°C)','Humidity\\xa0(%) high','Humidity\\xa0(%) low','Sea Level Press.\\xa0(hPa) high','Sea Level Press.\\xa0(hPa) low','Visibility\\xa0(km) high','Visibility\\xa0(km) low','Wind\\xa0(km/h) high','Wind\\xa0(km/h) low','WeatherEvent','Precip.\\xa0(mm) sum'],axis=1)\n",
    "Wther2012=Wther2012.drop(['Temp high (°C)','Temp low (°C)','Dew Point high (°C)','Dew Point low (°C)','Humidity\\xa0(%) high','Humidity\\xa0(%) low','Sea Level Press.\\xa0(hPa) high','Sea Level Press.\\xa0(hPa) low','Visibility\\xa0(km) high','Visibility\\xa0(km) low','Wind\\xa0(km/h) high','Wind\\xa0(km/h) low','WeatherEvent','Precip.\\xa0(mm) sum'],axis=1)\n",
    "Wther2013=Wther2013.drop(['Temp high (°C)','Temp low (°C)','Dew Point high (°C)','Dew Point low (°C)','Humidity\\xa0(%) high','Humidity\\xa0(%) low','Sea Level Press.\\xa0(hPa) high','Sea Level Press.\\xa0(hPa) low','Visibility\\xa0(km) high','Visibility\\xa0(km) low','Wind\\xa0(km/h) high','Wind\\xa0(km/h) low','WeatherEvent','Precip.\\xa0(mm) sum'],axis=1)\n",
    "Wther2014=Wther2014.drop(['Temp high (°C)','Temp low (°C)','Dew Point high (°C)','Dew Point low (°C)','Humidity\\xa0(%) high','Humidity\\xa0(%) low','Sea Level Press.\\xa0(hPa) high','Sea Level Press.\\xa0(hPa) low','Visibility\\xa0(km) high','Visibility\\xa0(km) low','Wind\\xa0(km/h) high','Wind\\xa0(km/h) low','WeatherEvent','Precip.\\xa0(mm) sum'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wther=pd.concat([Wther2009,Wther2010,Wther2011,Wther2012,Wther2013,Wther2014],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wther"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "year={2009:1,2010:2,2011:3,2012:4,2013:5,2014:6}\n",
    "month={'Jan':1, 'Feb':2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7, 'Aug':8, 'Sep':9,\n",
    "       'Oct':10, 'Nov':11, 'Dec':12}\n",
    "Wther[\"Year\"] = Wther[\"Year\"].map(year)\n",
    "Wther[\"Month\"] = Wther[\"Month\"].map(month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Dealing with Null values and changing categories to calculate average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wther[Wther.values  == \"-\"]\n",
    "#Wther=Wther.replace('-',np.NaN)\n",
    "#Wther[pd.isnull(Wther).any(axis=1)]\n",
    "#pd.to_numeric(Wthertry['Temp avg (°C)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Year',\n",
       " 'Month',\n",
       " 'Day',\n",
       " 'Temp avg (°C)',\n",
       " 'Dew Point avg (°C)',\n",
       " 'Humidity\\xa0(%) avg',\n",
       " 'Sea Level Press.\\xa0(hPa) avg',\n",
       " 'Visibility\\xa0(km) avg',\n",
       " 'Wind\\xa0(km/h) avg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Wther.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wther_avg=Wther.groupby(['Year','Month'])['Temp avg (°C)','Dew Point avg (°C)','Humidity\\xa0(%) avg','Sea Level Press.\\xa0(hPa) avg','Visibility\\xa0(km) avg','Wind\\xa0(km/h) avg'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wther[(Wther.Year==1) & (Wther.Month==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wther_avg=Wther_avg.values[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wther_fin=pd.DataFrame(Wther_avg,columns=['Temp_avg','Dew_Point_avg','Humidity_avg','Sea_Level_Press_avg','Visibility_avg','Wind_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wther_fin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Train_Kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Women=data[data['ProductCategory']=='WomenClothing']\n",
    "#print(data_Women.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Women=data_Women.fillna(value=3293)\n",
    "#data_Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Other=data[data['ProductCategory']=='OtherClothing']\n",
    "#data_Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Other=data_Other.fillna(value=1107)\n",
    "#data_Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Men=data[data['ProductCategory']=='MenClothing']\n",
    "#data_Men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Men=data_Men.fillna(value=674)\n",
    "#data_Men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data=pd.concat([data_Men,data_Women,data_Other])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin_data\n",
    "dept={'MenClothing':1,'OtherClothing':2,'WomenClothing':3}\n",
    "fin_data[\"ProductCategory\"] = fin_data[\"ProductCategory\"].map(dept)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "year={2009:1,2010:2,2011:3,2012:4,2013:5,2014:6}\n",
    "fin_data[\"Year\"] = fin_data[\"Year\"].map(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fin=fin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fin_Men=train_fin[train_fin['ProductCategory']==1].reset_index(drop=True)\n",
    "train_fin_Others=train_fin[train_fin['ProductCategory']==2].reset_index(drop=True)\n",
    "train_fin_Women=train_fin[train_fin['ProductCategory']==3].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_fin_Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "holi=pd.read_excel('Events_HolidaysData.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "holi_fin=holi.drop(['Year','Month'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holi_fin.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_men=pd.concat([train_fin_Men,holi_fin,Wther_fin],axis=1)\n",
    "full_others=pd.concat([train_fin_Others,holi_fin,Wther_fin],axis=1)\n",
    "full_women=pd.concat([train_fin_Women,holi_fin,Wther_fin],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = full_men['Sales(In ThousandDollars)']\n",
    "full_men.drop(labels=['Sales(In ThousandDollars)'], axis=1,inplace = True)\n",
    "full_men.insert(10, 'Sales(In ThousandDollars)', cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = full_others['Sales(In ThousandDollars)']\n",
    "full_others.drop(labels=['Sales(In ThousandDollars)'], axis=1,inplace = True)\n",
    "full_others.insert(10, 'Sales(In ThousandDollars)', cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = full_women['Sales(In ThousandDollars)']\n",
    "full_women.drop(labels=['Sales(In ThousandDollars)'], axis=1,inplace = True)\n",
    "full_women.insert(10, 'Sales(In ThousandDollars)', cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>Number_of_Holidays</th>\n",
       "      <th>Temp_avg</th>\n",
       "      <th>Dew_Point_avg</th>\n",
       "      <th>Humidity_avg</th>\n",
       "      <th>Sea_Level_Press_avg</th>\n",
       "      <th>Visibility_avg</th>\n",
       "      <th>Wind_avg</th>\n",
       "      <th>Sales(In ThousandDollars)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.096774</td>\n",
       "      <td>-7.806452</td>\n",
       "      <td>61.516129</td>\n",
       "      <td>1014.612903</td>\n",
       "      <td>12.387097</td>\n",
       "      <td>10.387097</td>\n",
       "      <td>936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>-6.857143</td>\n",
       "      <td>52.607143</td>\n",
       "      <td>1015.392857</td>\n",
       "      <td>13.642857</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>859.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.838710</td>\n",
       "      <td>-3.387097</td>\n",
       "      <td>56.096774</td>\n",
       "      <td>1019.612903</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>12.290323</td>\n",
       "      <td>921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>4.966667</td>\n",
       "      <td>64.466667</td>\n",
       "      <td>1013.566667</td>\n",
       "      <td>13.066667</td>\n",
       "      <td>11.766667</td>\n",
       "      <td>914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>18.161290</td>\n",
       "      <td>11.645161</td>\n",
       "      <td>71.870968</td>\n",
       "      <td>1014.709677</td>\n",
       "      <td>12.032258</td>\n",
       "      <td>8.838710</td>\n",
       "      <td>989.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  ProductCategory  Number_of_Holidays   Temp_avg  Dew_Point_avg  \\\n",
       "0     1      1                2                   2  -1.096774      -7.806452   \n",
       "1     1      2                2                   2   2.428571      -6.857143   \n",
       "2     1      3                2                   0   5.838710      -3.387097   \n",
       "3     1      4                2                   1  12.500000       4.966667   \n",
       "4     1      5                2                   2  18.161290      11.645161   \n",
       "\n",
       "   Humidity_avg  Sea_Level_Press_avg  Visibility_avg   Wind_avg  \\\n",
       "0     61.516129          1014.612903       12.387097  10.387097   \n",
       "1     52.607143          1015.392857       13.642857  12.250000   \n",
       "2     56.096774          1019.612903       14.000000  12.290323   \n",
       "3     64.466667          1013.566667       13.066667  11.766667   \n",
       "4     71.870968          1014.709677       12.032258   8.838710   \n",
       "\n",
       "   Sales(In ThousandDollars)  \n",
       "0                      936.0  \n",
       "1                      859.0  \n",
       "2                      921.0  \n",
       "3                      914.0  \n",
       "4                      989.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_others.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_men_X=full_men.values[:,:10]\n",
    "full_men_Y=full_men.values[:,10:]\n",
    "full_others_X=full_others.values[:,:10]\n",
    "full_others_Y=full_others.values[:,10:]\n",
    "full_women_X=full_women.values[:,:10]\n",
    "full_women_Y=full_women.values[:,10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72, 10), (72, 10), (72, 10))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_men_X.shape,full_others_X.shape,full_women_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Testing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('Test_Kaggle.csv')\n",
    "\n",
    "test_data=test_data.drop('Sales(In ThousandDollars)',axis=1)\n",
    "\n",
    "dept={'MenClothing':1,'OtherClothing':2,'WomenClothing':3}\n",
    "test_data[\"ProductCategory\"] = test_data[\"ProductCategory\"].map(dept)\n",
    "\n",
    "yeart={2015:7}\n",
    "test_data[\"Year\"] = test_data[\"Year\"].map(yeart)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_Men=test_data[test_data['ProductCategory']==1].reset_index(drop=True)\n",
    "test_data_Others=test_data[test_data['ProductCategory']==2].reset_index(drop=True)\n",
    "test_data_Women=test_data[test_data['ProductCategory']==3].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wther_test=Wther_fin[60:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "holi_test=holi_fin[60:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_men=pd.concat([test_data_Men,holi_test,Wther_test],axis=1)\n",
    "test_others=pd.concat([test_data_Others,holi_test,Wther_test],axis=1)\n",
    "test_women=pd.concat([test_data_Women,holi_test,Wther_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data_test=pd.concat([test_men,test_women,test_others])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.load('X_train.npy')\n",
    "Y_train=np.load('Y_train.npy')\n",
    "X_val=np.load('X_val.npy')\n",
    "Y_val=np.load('Y_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=pickle.load(open('model_129.868.dat','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='mae', init=None,\n",
      "             learning_rate=0.33333333333333, loss='ls', max_depth=3,\n",
      "             max_features=None, max_leaf_nodes=None,\n",
      "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=44, presort='auto',\n",
      "             random_state=None, subsample=1.0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_pred_test = model.predict(big_data_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=[]\n",
    "for i in range(12):\n",
    "    sub.append(Y_pred_test[i+12])\n",
    "    sub.append(Y_pred_test[i])\n",
    "    sub.append(Y_pred_test[i+24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsub=np.asarray(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Big Data Test\n",
    "\n",
    "#fil=open('Retail_11.csv','w')\n",
    "#fil=open('Retail_12.csv','w') ###new grid search\n",
    "#fil=open('Retail_13.csv','w')  ## split=0.15, max_depth=None\n",
    "#fil=open('Retail_14.csv','w')  ## split=0.15, max_depth=4\n",
    "#fil=open('Retail_15.csv','w')  ## minor changes\n",
    "#fil=open('Retail_16.csv','w')  ## Adaboost\n",
    "#fil=open('Retail_16.csv','w')  ## gb 0.4 ,900,ls,mae again\n",
    "#fil=open('Retail_17.csv','w')  ## gb 0.111 ,850,ls,mae\n",
    "#fil=open('Retail_17_recreate.csv','w')  ### Recreating Retail_17 for submission\n",
    "#fil=open('Retail_18.csv','w')  ### XGBoost\n",
    "#fil=open('Retail_19.csv','w')  ### XGBoost with RMS=104\n",
    "#fil=open('Retail_20.csv','w')  ### XGBoost with lr=0.15000...2,nestimator=100\n",
    "#fil=open('Retail_21.csv','w')  ### gb 0.1111 ,900,ls,mae\n",
    "#fil=open('Retail_22.csv','w')  ### gb 0.1111 ,2000,ls,mae\n",
    "#fil=open('Retail_23.csv','w')  ### gb 0.15000000000002 ,2000,ls,mae,RMS=105\n",
    "#fil=open('Retail_24.csv','w')  ### gb 0.3333333333333333 ,100,ls,mae,RMS=94\n",
    "#fil=open('Retail_25.csv','w')  ### xgbr 0.111111111111111 ,725\n",
    "#fil=open('Retail_26.csv','w')  ### gb 0.3333333333333333 ,29,ls,mae\n",
    "#fil=open('Retail_27.csv','w')  ### gb 0.3333333333333333 ,40,ls,mae\n",
    "#fil=open('Retail_28.csv','w')  ### gb 0.3333333333333333 ,16,ls,mae,RMS=111\n",
    "#fil=open('Retail_29.csv','w')  ### gb 0.3333333333333333 ,1111,ls,mae\n",
    "#fil=open('Retail_30.csv','w')\n",
    "#fil=open('Retail_31.csv','w')\n",
    "#fil=open('Retail_32.csv','w')\n",
    "#fil=open('Retail_33.csv','w')\n",
    "#fil=open('Retail_34.csv','w')\n",
    "#fil=open('Retail_35.csv','w')\n",
    "#fil=open('Retail_36.csv','w')\n",
    "#fil=open('Retail_37.csv','w')\n",
    "#fil=open('Retail_38.csv','w')  #####Random state=40,n_estimators=44,gb 0.3333333333333333 ,ls,mae,split=.11\n",
    "#fil=open('Retail_39.csv','w')  #####Random state=40,n_estimators=44,gb 0.3333333333333333 ,ls,mae,split=.10\n",
    "#fil=open('Retail_try.csv','w')     #####Random State=42,n_estimators=44,gb 0.3333333333333333 ,ls,mae,split=.10\n",
    "#fil=open('Retail_try1.csv','w')       #####Random State=42,n_estimators=45,gb 0.3333333333333333 ,ls,mae,split=.10\n",
    "#fil=open('Retail_40.csv','w')       #####Random State=42,n_estimators=44,gb 0.1111 ,ls,mae,split=.01,RMS=52\n",
    "#fil=open('Retail_41.csv','w')\n",
    "#fil=open('Retail_42.csv','w')\n",
    "fil=open('Submit1.csv','w')\n",
    "fil.write('Year,Sales(In ThousandDollars)\\n')\n",
    "for i in range(nsub.shape[0]-1):\n",
    "   fil.write('%d,%d\\n'%(i+1,nsub[i]))\n",
    "fil.write('%d,%d'%(i+2,nsub[i+1]))\n",
    "fil.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
